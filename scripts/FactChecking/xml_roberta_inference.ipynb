{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0617c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/, https://download.pytorch.org/whl/cu116\n",
      "Collecting torch==1.13.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl (1977.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m420.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.14.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp39-cp39-linux_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.13.1\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from torch==1.13.1+cu116) (4.3.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (from torchvision==0.14.1+cu116) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from torchvision==0.14.1+cu116) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from torchvision==0.14.1+cu116) (7.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->torchvision==0.14.1+cu116) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->torchvision==0.14.1+cu116) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->torchvision==0.14.1+cu116) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->torchvision==0.14.1+cu116) (2022.6.15)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch, torchvision, torchaudio\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-forecasting 0.10.2 requires optuna<3.0.0,>=2.3.0, but you have optuna 3.0.0 which is incompatible.\n",
      "pytorch-forecasting 0.10.2 requires pandas<2.0.0,>=1.3.0, but you have pandas 1.2.3 which is incompatible.\n",
      "pytorch-forecasting 0.10.2 requires scipy<2.0,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "pytorch-lightning 1.6.5 requires protobuf<=3.20.1, but you have protobuf 4.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.13.1+cu116 torchaudio-0.13.1+cu116 torchvision-0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb339f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 31 09:26:57 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9b6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Collecting accelerate\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/78/59/cce8c37babc77ca8ae97a0d7f7d1d9434f352458844ae349c0e77db92132/accelerate-0.9.0-py3-none-any.whl (106 kB)\n",
      "     |████████████████████████████████| 106 kB 41.5 MB/s            \n",
      "\u001b[?25hCollecting torch>=1.4.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/a4/54/81b1c3c574a1ffde54b0c82ed2a37d81395709cdd5f50e59970aeed5d95e/torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 7.4 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from accelerate) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->accelerate) (0.8)\n",
      "Installing collected packages: torch, accelerate\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed accelerate-0.9.0 torch-1.10.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Collecting transformers\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/8f/e9/c2b4c823b3959d475a570c1bd2df4125478e2e37b96fb967a87933ae7134/transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 56.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (5.4.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/18/02/d7ba6749c5b7a6f75d6cf287942c800f63e98440dd03e406ed5f01c2b9db/regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "     |████████████████████████████████| 759 kB 56.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/c8/df/1b454741459f6ce75f86534bdad42ca17291b14a83066695f7d2c676e16c/huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 8.8 MB/s             \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/28/78/fef8d089db5b97546fd6d1ff2e813b8544e85670bf3a8c378c9d0250b98d/sacremoses-0.0.53.tar.gz (880 kB)\n",
      "     |████████████████████████████████| 880 kB 55.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (4.8.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/36/22/26b08c841c0493908b4be6960ec2be14a21d1ec0f42ae0cedbca5599ad3d/tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 45.4 MB/s            \n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/84/ce/8916d10ef537f3f3b046843255f9799504aa41862bfa87844b9bdc5361cd/filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm>=4.27->transformers) (5.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=dfade370de6f7ed4acd6f763a86188b8d59a57addb4e7377363fcd9515b4b3e4\n",
      "  Stored in directory: /home/nikola_milosevic/.cache/pip/wheels/0e/ee/ad/112f735905321e5f150a1decd50c52dade8b15ac9e115097af\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "\u001b[33m  WARNING: The script sacremoses is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed filelock-3.4.1 huggingface-hub-0.4.0 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Collecting tensorflow\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/fe/e2/20b693b5cc699f8116075379d57c4628502f58f96aa759209b77be047882/tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |█████████████████▍              | 249.3 MB 79.5 MB/s eta 0:00:03     |████████████████████████████████| 458.3 MB 7.3 kB/s             \n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/97/75/f5e61fb67ecbe45c31035b17562464e11b91a2b8a351bae5ca0db2969e3b/absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 1.6 MB/s            \n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 5.1 MB/s             \n",
      "\u001b[?25hCollecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/a0/20/a59a30c32330e4ff704faa4273b251db042d495e0c367bcdf045c6fe26e9/tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 53.8 MB/s            \n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 7.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
      "Collecting clang~=5.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/32/12/e17c1220f8ca587add2e076ebb28b6c4551fcc730e3c69a5f49679ad28e9/clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.37.1)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/68/dc/31397ed1d4594a2b1495bc4e4cdc4fdb80c02a1e2593b45ac56a58e9b431/grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "     |████████████████████████████████| 4.6 MB 57.9 MB/s            \n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 2.1 MB/s             \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/5a/38/04d9b7fb53acdf861df2c4505fa96b06c779817a511e94b8882d284ba360/keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 60.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.19.4)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/c8/54/1b2f1e22a2670546cc02e4df1b80425edaee02133173bb91aa0f6d3d0293/tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 49.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/f4/f3/22afbdb20cc4654b10c98043414a14057cd27fdba9d4ae61cea596000ba2/Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "     |████████████████████████████████| 289 kB 62.9 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 67.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.6.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/fb/7a/1b3eb54caee1b8c73c2c3645f78a382eca4805a301a30c64a078e736e446/google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 40.3 MB/s            \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/f3/df/ca72f352e15b6f8ce32b74af029f1189abffb906f7c137501ffe69c98a65/Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 5.8 MB/s             \n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/e0/68/e8ecfac5dd594b676c23a7f07ea34c197d7d69b3313afdf8ac1b0a9905a2/tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 64.7 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/b1/0e/0636cc1448a7abc444fb1b3a63655e294e0d2d49092dc3de05241be6d43c/google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/ea/c1/4740af52db75e6dbdd57fc7e9478439815bbac549c1c05881be27d19a17d/cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 44.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Building wheels for collected packages: clang, termcolor, wrapt\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=7d32e6b7a06be733ad46641368f85ba4d440aa539f19608835d21dbe83248738\n",
      "  Stored in directory: /home/nikola_milosevic/.cache/pip/wheels/22/d6/de/275fb3a91015721700be0a043630a591a3f757ef1c5206f24f\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=716ed3f0bf72ab1efae907db2327121b4c45e01de53df48f5cf4511d89aa4741\n",
      "  Stored in directory: /home/nikola_milosevic/.cache/pip/wheels/5f/cb/ee/562d050eac20f94344dfffdc9d256802844d33f99c625dbe5f\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=67550 sha256=61e620153d873a108cff7e84db92c4fb904f64a0857135a73b306a808825e920\n",
      "  Stored in directory: /home/nikola_milosevic/.cache/pip/wheels/4f/d2/7f/3806d408046bb97e677815fb3fddee4cbdd218b467b6e959fb\n",
      "Successfully built clang termcolor wrapt\n",
      "Installing collected packages: typing-extensions, six, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "\u001b[33m  WARNING: The script markdown_py is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.13.9 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.11.7 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.48.2 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.7 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 six-1.15.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-2.0.3 wrapt-1.12.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Collecting datasets\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/13/68/8f123cf1b84fc32d749357b2c7ed6e9e61c06246965ba7f6f7a78cba54e9/datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "     |████████████████████████████████| 365 kB 34.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.27.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/3c/f7/3925be6f7c251b331095d3e7302fdf3c7599284b5a616bd4c90fca7ace45/responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/72/b5/01d4730395cf27ec679debfeab60efaafebd10177ff5b04eef5d530a6bf8/pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "     |████████████████████████████████| 25.6 MB 68.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.4)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/f6/90/32e53b96067954c2f916667f5a11634aeabef8ed70e83133ed8037b8111b/fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 34.9 MB/s            \n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/df/d0/c3011a5bb77f307e68682a5046cce1a2c6591267bf24b5bf3fc4130bb39d/multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "     |████████████████████████████████| 106 kB 38.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in ./.local/lib/python3.6/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from datasets) (4.8.3)\n",
      "Collecting aiohttp\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/b8/b6/6dd2c1f2915b39414f753c276f54dc2890612347a78e21c135fa3c76fd15/aiohttp-3.8.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (985 kB)\n",
      "     |████████████████████████████████| 985 kB 67.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.19.5)\n",
      "Collecting xxhash\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/09/81/c52beb776995b9bc3b5b652b93a03fa3f08f85a902fa6008cdb2500855d4/xxhash-3.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "     |████████████████████████████████| 211 kB 61.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.6/site-packages (from responses<0.19->datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm>=4.62.1->datasets) (5.4.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/fa/cb/8791922f5ec97b9ebec516d062c0e113da963568ffe2c7c04d8187ab7cc3/yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "     |████████████████████████████████| 270 kB 63.5 MB/s            \n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/51/3f/f67395ff0090b9f2835838a1f61c3e840baac70fd65bae762095dead48b2/frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "     |████████████████████████████████| 191 kB 23.8 MB/s            \n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/82/43/81ddfbcfbdfaeaa0624f36dcb715dc8135562377b3292e93b0315a861e92/multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "     |████████████████████████████████| 159 kB 36.3 MB/s            \n",
      "\u001b[?25hCollecting idna-ssl>=1.0\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Building wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3178 sha256=cf96d68b6b30790b103f7b0dfe9ab7f8257b7b965a4c132ffa6c2ad5402fe1b2\n",
      "  Stored in directory: /home/nikola_milosevic/.cache/pip/wheels/c6/e8/b8/9e780c728293f1a31c46e19023079a246a1943beeba210fdd6\n",
      "Successfully built idna-ssl\n",
      "Installing collected packages: multidict, frozenlist, yarl, idna-ssl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, pyarrow, multiprocess, datasets\n",
      "\u001b[33m  WARNING: The script plasma_store is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.4.0 frozenlist-1.2.0 fsspec-2022.1.0 idna-ssl-1.1.0 multidict-5.2.0 multiprocess-0.70.12.2 pyarrow-6.0.1 responses-0.17.0 xxhash-3.2.0 yarl-1.7.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement evaluate (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for evaluate\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U accelerate\n",
    "! pip3 install -U transformers\n",
    "! pip3 install -U tensorflow\n",
    "! pip3 install datasets\n",
    "! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c97c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.6/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in ./.local/lib/python3.6/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.6/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.local/lib/python3.6/site-packages (from datasets) (2022.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./.local/lib/python3.6/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.6/site-packages (from datasets) (0.17.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from datasets) (4.8.3)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.6/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.6/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.6/site-packages (from responses<0.19->datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm>=4.62.1->datasets) (5.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (1.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in ./.local/lib/python3.6/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2022.1)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebfef768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Collecting numpy==1.23.5\n",
      "  Downloading https://artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/packages/packages/4c/b9/038abd6fbd67b05b03cb1af590cfc02b7f1e5a37af7ac6a868f5093c29f5/numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.1\n",
      "    Uninstalling numpy-1.22.1:\n",
      "      Successfully uninstalled numpy-1.22.1\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.9 are installed in '/home/nikola_milosevic/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-forecasting 0.10.2 requires optuna<3.0.0,>=2.3.0, but you have optuna 3.0.0 which is incompatible.\n",
      "pytorch-forecasting 0.10.2 requires pandas<2.0.0,>=1.3.0, but you have pandas 1.2.3 which is incompatible.\n",
      "pytorch-forecasting 0.10.2 requires scipy<2.0,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "pytorch-lightning 1.6.5 requires protobuf<=3.20.1, but you have protobuf 4.24.4 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy==\"1.23.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b6aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.local/lib/python3.9/site-packages (from evaluate) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.9/site-packages (from evaluate) (1.26.1)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.9/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from evaluate) (1.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.9/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.local/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.local/lib/python3.9/site-packages (from evaluate) (0.17.3)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from packaging->evaluate) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pandas->evaluate) (2022.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb2cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "corpus = load_dataset(\"allenai/scifact\",\"corpus\")\n",
    "dataset = load_dataset(\"allenai/scifact\",\"claims\")\n",
    "corpus2 = {}\n",
    "for doc in corpus['train']:\n",
    "  title = doc['title']\n",
    "  abstract = ''\n",
    "  for sent in doc['abstract']:\n",
    "    abstract = abstract + sent + ' '\n",
    "  corpus2[doc['doc_id']] = {'title':title,'abstract':abstract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6277edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
    "def preprocess_function(examples):\n",
    "    max_input_length = 512\n",
    "    return tokenizer(examples[\"text\"], truncation=True,padding=True,max_length=max_input_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d90b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "id2label = {0: \"NO_EVIDENCE\", 1: \"SUPPORT\",2:\"CONTRADICT\"}\n",
    "label2id = {\"NO_EVIDENCE\": 0, \"SUPPORT\": 1,\"CONTRADICT\":2}\n",
    "new_dataset = pd.DataFrame(columns=['claim','abstract','label'])\n",
    "new_dataset2 = pd.DataFrame(columns=['text','label'])\n",
    "cnt = 0\n",
    "for item in dataset['train']:\n",
    "  doc_id = item['cited_doc_ids'][0]\n",
    "  if item['evidence_label'] == '':\n",
    "    label = \"NO_EVIDENCE\"\n",
    "  if item['evidence_label'] == 'SUPPORT':\n",
    "    label = 'SUPPORT'\n",
    "  if item['evidence_label'] == 'CONTRADICT':\n",
    "    label = 'CONTRADICT'\n",
    "  claim = item['claim']\n",
    "  abstract = corpus2[doc_id]['title']+'\\n'+corpus2[doc_id]['abstract']\n",
    "  new_dataset.loc[cnt] = pd.Series({'claim':claim, 'abstract':abstract, 'label':label2id[label]})\n",
    "  new_dataset2.loc[cnt] = pd.Series({'text':tokenizer.cls_token+claim+tokenizer.sep_token+abstract, 'label':label2id[label]})\n",
    "  cnt = cnt + 1\n",
    "\n",
    "\n",
    "new_dataset2 = new_dataset2.reset_index(drop=True)\n",
    "from datasets import Dataset\n",
    "dataset_new = Dataset.from_pandas(new_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274d76c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01891326904296875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 1134,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d63fb0b25d47c0af4f1a60c7b29ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1134 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018527746200561523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 127,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f91329a59840f4a3a571d26fa1ca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_new=dataset_new.train_test_split(test_size=0.1)\n",
    "tokenized = dataset_new.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57b7315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 09:32:32.809294: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-31 09:32:32.809385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-31 09:32:32.809433: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-31 09:32:32.818091: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 09:32:33.929930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ddc1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\", num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06f9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ea97ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"SCIFACT_inference_model\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    num_train_epochs=15,\n",
    "    save_total_limit = 1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa54ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5670' max='5670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5670/5670 42:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.048528</td>\n",
       "      <td>0.472441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.038200</td>\n",
       "      <td>1.396432</td>\n",
       "      <td>0.606299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.916760</td>\n",
       "      <td>0.826772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>0.752377</td>\n",
       "      <td>0.842520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>1.067203</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.959884</td>\n",
       "      <td>0.842520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.869064</td>\n",
       "      <td>0.866142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>1.316232</td>\n",
       "      <td>0.826772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>1.319961</td>\n",
       "      <td>0.858268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>1.156625</td>\n",
       "      <td>0.874016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>1.156820</td>\n",
       "      <td>0.881890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>1.201310</td>\n",
       "      <td>0.866142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>1.155708</td>\n",
       "      <td>0.881890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.304449</td>\n",
       "      <td>0.866142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>1.249618</td>\n",
       "      <td>0.881890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5670, training_loss=0.33061368776587163, metrics={'train_runtime': 2549.3312, 'train_samples_per_second': 6.672, 'train_steps_per_second': 2.224, 'total_flos': 1.585220605129728e+16, 'train_loss': 0.33061368776587163, 'epoch': 15.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd21e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c5c0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a674ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-forecasting @ file:///home/conda/feedstock_root/build_artifacts/pytorch-forecasting_1653324759146/work\r\n",
      "pytorch-lightning @ file:///home/conda/feedstock_root/build_artifacts/pytorch-lightning_1658040017668/work\r\n",
      "torch==1.10.2\r\n",
      "torchmetrics @ file:///home/conda/feedstock_root/build_artifacts/torchmetrics_1658640326316/work\r\n",
      "torchvision==0.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3947a571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b58087",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = []\n",
    "for pred in predictions[0]:\n",
    "  classifications.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef55e996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " NO_EVIDENCE       0.91      0.88      0.90        34\n",
      "     SUPPORT       0.91      0.88      0.89        58\n",
      "  CONTRADICT       0.82      0.89      0.85        35\n",
      "\n",
      "    accuracy                           0.88       127\n",
      "   macro avg       0.88      0.88      0.88       127\n",
      "weighted avg       0.88      0.88      0.88       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['NO_EVIDENCE', 'SUPPORT', 'CONTRADICT']\n",
    "print(classification_report(tokenized[\"test\"]['label'], classifications, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a7a8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  2,  2],\n",
       "       [ 2, 51,  5],\n",
       "       [ 1,  3, 31]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(tokenized[\"test\"]['label'], classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6a88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"SciFact_xlm-roberta-large_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb7e040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "shutil.rmtree(\"SCIFACT_inference_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "209f354d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018233776092529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 1,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60c31dbdec248bc9e3eaf92dd209d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataset3 = pd.DataFrame(columns=['text'])\n",
    "claim = \"X-linked genes, particularly those related to chromatin structure/remodeling, segregation, and ribosomal biogenesis and translational control, may also play key regulatory roles in breast carcinogenesis\"\n",
    "abstract = \"\"\"While contribution of X chromosome in the susceptibility of prostate and ovarian cancer has been demonstrated, the role of X-linked genes in breast carcinogenesis is not clearly known. This study investigated and compared the X-linked gene expression profiles of MMTV-c-myc transgenic mammary tumor (MT) or MMTV-c-myc/MT-tgf-alpha double transgenic mouse mammary tumor (DT) to lactating mammary gland. cDNA microarray analysis using the Affymetrix system identified 1081 genes localized on the X chromosome with 174 and 194 genes at +/-2-fold change levels in MT and DT samples, respectively. Differentially expressed X-linked genes were predominantly related to chromatin structure/remodeling (e.g., Hdac8, Suv39h1, RbAp46 and Adr1), segregation (e.g., CENP-I and smc111) and, ribosomal biogenesis and translational control (e.g., Dkc1, Rpl44, Rpl39, Eif2s3x, Gspt2 and Rsk4). Confirmation of microarray data by semi-quantitative and quantitative RT-PCR in selected X-linked genes also showed similar pattern. In addition, the expression pattern of two chromosomal regions, XE3 and XF5, suggests that XE3 may have escaped from inactivation and XF5 subjected to inactivation. In conclusion, our data suggest that X-linked genes may play the key regulatory roles in the maintenance of chromatin structure, accurate chromosomal segregation and translational control; hence deregulation of X-linked genes may promote mammary gland tumorigenesis by promoting genetic instability and cell proliferation. Increased understanding of the role of X-linked genes and genetic pathways will provide the strategies to develop the molecular therapeutics to treat and prevent reproductive related cancers.\"\"\"\n",
    "new_dataset3.loc[0] = pd.Series({'text':tokenizer.cls_token+claim+tokenizer.sep_token+abstract})\n",
    "new_dataset3 = new_dataset3.reset_index(drop=True)\n",
    "from datasets import Dataset\n",
    "dataset_new = Dataset.from_pandas(new_dataset3)\n",
    "tokenized = dataset_new.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a302e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['SUPPORT']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = trainer.predict(tokenized)\n",
    "classifications = []\n",
    "for pred in prediction[0]:\n",
    "  classifications.append(id2label[np.argmax(pred)])\n",
    "classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "814a3e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/nikola_milosevic/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "879db9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01946234703063965,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 2239709617,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aed28bc9de64107b0b5f0f5167fe77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03825569152832031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 3 LFS files",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d90b2a9f71491f86ff6e2b1ff516f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01844620704650879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer.json",
       "rate": null,
       "total": 17082941,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aea8c40940a42f085b4292e254268d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01912379264831543,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "training_args.bin",
       "rate": null,
       "total": 4091,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392cc3a9adc14eae9d3eda93bfbd7d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/nikolamilosevic/SCIFACT_inference_model/tree/main/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"SciFact_xlm-roberta-large_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54646b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://dataatscale-sas:****@artifactory.bayer.com/artifactory/api/pypi/dataatscale-sas-virtual/simple/\n",
      "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.9/site-packages (0.17.3)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2022.6.15)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1bf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
